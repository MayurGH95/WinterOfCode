{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b477c-3d6e-48ab-b76b-620788904de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a3453a-0202-4ed0-b14b-92db35f80103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def extract_traindata(csv_path):\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "        else:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    X = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:, -1].values\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def append_numpy_to_csv(array_data, file_name, delimiter=',', include_header=False):\n",
    "    try:\n",
    "        df_new_data = pd.DataFrame(array_data)\n",
    "\n",
    "        df_new_data.to_csv(\n",
    "            file_name,\n",
    "            mode='a',          \n",
    "            sep=delimiter,\n",
    "            header=include_header, \n",
    "            index=False       \n",
    "        )\n",
    "        print(f\"Successfully appended NumPy array data to '{file_name}'.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while appending to CSV: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584ca48b-8bb4-4b74-81b1-035f882d28f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_testdata(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "    X = df.iloc[:, :].values\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecd778b-82ab-4223-96c6-d84954d298dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_cost(X,y,w,b,lamda):\n",
    "    m,n = X.shape\n",
    "    f_wb=np.dot(X,w)+b\n",
    "    loss=(f_wb-y)**2\n",
    "    cost=np.sum(loss)/(2*m)\n",
    "    cost_w=(lamda/(2*m))*np.sum(w**2)\n",
    "\n",
    "    total_cost = cost+cost_w\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dc68df-3ae7-4d99-8915-f5b766447ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_gradient(X,y,w,b,lamda):\n",
    "    m,n = X.shape\n",
    "    f_wb=np.dot(X,w)+b\n",
    "    error=(f_wb-y)\n",
    "    dj_dw=np.dot(X.T,error)/m\n",
    "    dj_db=np.sum(error)/m\n",
    "    dj_dw=dj_dw+(lamda/m)*w\n",
    "    return dj_dw,dj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6137ab16-a56e-4a60-899e-4b66463a8590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X,y,w_in,b_in,alpha=0.001,iters=1000,lamda=0.0,batch_size=128,optimizer=\"adam\",beta1=0.9,beta2=0.999,eps=1e-8,tol=1e-6,patience=20,shuffle=True):\n",
    "    m,n=X.shape\n",
    "    w=w_in.copy()\n",
    "    b=b_in\n",
    "    J_data=[]\n",
    "    best_cost = np.inf\n",
    "    wait = 0\n",
    "\n",
    "    vw = np.zeros_like(w)\n",
    "    vb = np.zeros_like(b)\n",
    "    sw = np.zeros_like(w)\n",
    "    sb = np.zeros_like(b)\n",
    "\n",
    "    J_data = []\n",
    "    best_cost = np.inf\n",
    "    wait = 0\n",
    "    t = 0\n",
    "    for epoch in range(iters):\n",
    "\n",
    "        if shuffle:\n",
    "            rng = np.random.default_rng(42 + epoch)\n",
    "            perm = rng.permutation(m)\n",
    "\n",
    "            X = X[perm]\n",
    "            y = y[perm]\n",
    "\n",
    "        for i in range(0, m, batch_size):\n",
    "            X_batch = X[i:i+batch_size]\n",
    "            Y_batch = y[i:i+batch_size]\n",
    "\n",
    "            dj_dw, dj_db = comp_gradient(\n",
    "                X_batch, Y_batch, w, b, lamda\n",
    "            )\n",
    "\n",
    "            if optimizer == \"adam\":\n",
    "                t += 1\n",
    "\n",
    "                #momentum\n",
    "                vw = beta1 * vw + (1 - beta1) * dj_dw\n",
    "                vb = beta1 * vb + (1 - beta1) * dj_db\n",
    "\n",
    "                #RMSProp\n",
    "                sw = beta2 * sw + (1 - beta2) * (dj_dw ** 2)\n",
    "                sb = beta2 * sb + (1 - beta2) * (dj_db ** 2)\n",
    "\n",
    "                #bias correction\n",
    "                vw_hat = vw / (1 - beta1 ** t)\n",
    "                vb_hat = vb / (1 - beta1 ** t)\n",
    "                sw_hat = sw / (1 - beta2 ** t)\n",
    "                sb_hat = sb / (1 - beta2 ** t)\n",
    "\n",
    "                #update\n",
    "                w -= alpha * vw_hat / (np.sqrt(sw_hat) + eps)\n",
    "                b -= alpha * vb_hat / (np.sqrt(sb_hat) + eps)\n",
    "\n",
    "            else:  #normal GD\n",
    "                w -= alpha * dj_dw\n",
    "                b -= alpha * dj_db\n",
    "\n",
    "        #adding cost to list of cost history\n",
    "        cost = comp_cost(X, y, w, b, lamda)\n",
    "        J_data.append(cost)\n",
    "\n",
    "        #detecting divergence\n",
    "        if np.isnan(cost) or np.isinf(cost):\n",
    "            print(\"Training diverged. Stopping early.\")\n",
    "            break\n",
    "\n",
    "        #early stopping\n",
    "        if best_cost - cost > tol:\n",
    "            best_cost = cost\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "\n",
    "        if wait >= patience:\n",
    "            print(f\"Early stopping at iteration {epoch}\")\n",
    "            break\n",
    "\n",
    "        #printing iteration, cost and learning rate\n",
    "        if epoch % max(1, iters // 10) == 0:\n",
    "            print(f\"Epoch {epoch} | Cost: {cost:.6f}\")\n",
    "\n",
    "    return w,b,J_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
